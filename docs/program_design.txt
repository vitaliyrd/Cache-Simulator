Classes:
CPU - responsible for calling memory read/write operations
Cache - responsible for returning/fetching the cached contents of memory
System - responsible for calling CPU to execute instructions (in this case memory accesses)
Memory - responsible for fetching the contents of memory
Main program - user front end that controls the System instance

CPU:
+ L1 Instruction Cache
+ L1 Data Cache
+ L2 Cache
+ Reference to System
- void execute(Instruction)

Instruction: just a wrapper class that holds the specs of an instruction

Cache:
+ int accesses
+ int misses
+ Array of the cache contents
- boolean locate(int location)
- void fetch(int location)

System:
+ Array of the CPUs
+ Array of the memories
+ L3 Cache
+ MESI Indicator for the L3 Cache
- void execute(enum instruction, int address)
- toString()

Memory:
+ int reads
+ int writes
+ int size (in bytes)
+ int readLatency
+ int writeLatency
- void read(int location)
- void write(int location)

Main program:
+ System instance
loads memory trace file
execute all reads/writes based on trace file
print summary

Assumptions:
- When a miss happens, we don't count the time it takes for everything to be fetched back into the caches. In other words,
we only count the access time of each level of memory as we look for the data. When the data is found, we use the total time
up to and including the level of memory where the data was found. For example, if the hit occurred first at the 1LM:
Time = L1d latency + L2 latency + L3 latency + 1LM latency
What I'm trying to say is that I don't think we need to account for the time it takes to update all of the caches with
this data that was acquired at 1LM. In an ideal system when the 1LM is accessed it will in one moment update all of the
caches AND send the data to the CPU.